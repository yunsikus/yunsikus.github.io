---  
layout: post  
title: "Hadoop Ecosystem(Hdfs, MapReduce)"  
subtitle: "Hadoop Ecosystem(Hdfs, MapReduce)"  
categories: Data
tags: Engineering Hadoop HDFS MapReduce Spark
comments: true  


---  
## 하둡이란?

하둡은 대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈 소스 프레임워크. 하둡은 구글이 논문으로 발표한 GFS(Google File System) 과 맵리듀스(MapReduce)를 2005년 더그커팅이 구현한 결과물이다. 하둡은 분산시스템인 HDFS(Hadoop Distributed File System)에 데이터를 저장하고, 맵리듀스를 이용해 데이터를 처리한다.


## Hadoop의 3대 요소
  - 분산파일시스템(`HDFS`) - for 대용량
  - 분산병렬처리(`MapReduce`) - for 빠른계산
  - 하둡클러스터 자원관리시스템(`YARN`)


## 분산파일시스템(HDFS)

#### 네임노드와 데이터노드

하둡 분산 파일 시스템 클러스터는 일반적으로 `네임노드` 를 담당하는 서버가 한대 존재하며, 하나의 노드에 붙은 스토리지를 관리하는 수 많은 `데이터 노드` 로 구성이 됩니다. `데이터 노드` 에 `블록` 단위의 데이터들이 분산 저장되고 `네임노드` 의 관리에 의해 읽기 및 쓰기를 수행합니다.


- **네임노드(Master Node)** : 파일과 디렉토리에 대한 메타 데이터 정보를 저장. 이를 통해 데이터 저장 기능을 관리하고 조정. 장애를 대비해 보조 네임노드가 운영됨
- **데이터노드(Slave Node)** : 네임노드의 지시에 따라, 데이터들을 분산 저장하는 저장소
- **블록** : 64MB 혹은 128MB 단위의 블록으로 쪼개지고 복제(3copy)되어 저장이 됨 

![hdfs1](https://yunsikus.github.io/assets/img/hadoop/hdfs1.jpeg)

#### HDFS에 저장된 파일 읽기

-  `네임노드`에 파일에 대한 정보를 요청(filename, Datanode Name)  
-  파일에 대한 모든 `블록`의 목록, 각 블록의 `데이터 노드` 목록 정보를 수신
-  쪼개진 `블록`들을 하나로 합친 후 client에 전달  

![hdfs2](https://yunsikus.github.io/assets/img/hadoop/hdfs_read.jpg)



### 장애처리

HDFS는 오류나 장애에 대한 해결책을 가지고 있습니다.

  - HeartBeat & Block report : 데이터노드에서 노드가 살아 있는 것을 알리기 위해 3초에 한번씩 네임노드에 HeartBeat 신호를 보냄.
  - Block report
  - checksum : 데이터를 저장할때 checksum을 같이 저장.
  - Data Replication :

#### 복사본 배치 전략
