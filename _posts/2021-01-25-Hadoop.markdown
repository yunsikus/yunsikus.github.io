---  
layout: post  
title: "Hadoop Ecosystem(Hdfs, MapReduce)"  
subtitle: "Hadoop Ecosystem(Hdfs, MapReduce)"  
categories: Data
tags: Engineering Hadoop HDFS MapReduce Spark
comments: true  


---  
## 하둡이란?

하둡은 대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈 소스 프레임워크. 하둡은 구글이 논문으로 발표한 GFS(Google File System) 과 맵리듀스(MapReduce)를 2005년 더그커팅이 구현한 결과물이다. 하둡은 분산시스템인 HDFS(Hadoop Distributed File System)에 데이터를 저장하고, 맵리듀스를 이용해 데이터를 처리한다.


## Hadoop의 3대 요소
  - 분산파일시스템(`HDFS`) - for 대용량
  - 분산병렬처리(`MapReduce`) - for 빠른계산
  - 하둡클러스터 자원관리시스템(`YARN`)


## 분산파일시스템(HDFS)

#### HDFS 주요특징
- 대용량 데이터 저장
- 데이터 무결성
- 장애 허용
- 데이터 스트리밍



#### 네임노드와 데이터노드

하둡 분산 파일 시스템 클러스터는 일반적으로 `네임노드` 를 담당하는 서버가 한대 존재하며, 하나의 노드에 붙은 스토리지를 관리하는 수 많은 `데이터 노드` 로 구성이 됩니다. `데이터 노드` 에 `블록` 단위의 데이터들이 분산 저장되고 `네임노드` 의 관리에 의해 읽기 및 쓰기를 수행합니다.


- **네임노드(Master Node)** :
  -  **데이터 노드 관리** : 하트비트와 블록리포트를 바탕으로 데이터 노드를 모니터링, 일정시간 하트비트가 도착하지 않으면 서버 장애 판단.
  - **블록 관리** : 장애가 발생한 데이터 노드의 블록을 새로운 데이터 노드로 복제. 용량이 부족한 데이터 노드가 있으면 여유가 있는 데이터 노드로 블록을 이동.
- **데이터노드(Slave Node)** : 네임노드의 지시에 따라, 데이터들을 분산 저장하는 저장소
- **블록** : 64MB 혹은 128MB 단위의 블록으로 쪼개지고 복제(3copy)되어 저장이 됨. 블록 단위가 보통 디스크의 단위보다 큰 이유는 탐색비용을 최소화할 수 있으며, 메타데이터의 크기를 줄일 수 있기 때문.

![hdfs1](https://yunsikus.github.io/assets/img/hadoop/hdfs1.jpeg)

#### HDFS에 저장된 파일 읽기

-  `네임노드`에 파일에 대한 정보를 요청(filename, Datanode Name)  
-  파일에 대한 모든 `블록`의 목록, 각 블록의 `데이터 노드` 목록 정보를 수신
-  쪼개진 `블록`들을 하나로 합친 후 client에 전달  

![hdfs2](https://yunsikus.github.io/assets/img/hadoop/hdfs_read.jpg)



### 장애처리

HDFS는 오류나 장애에 대한 해결책을 가지고 있습니다.

  - **HeartBeat**: 데이터노드에서 노드가 살아 있는 것을 알리기 위해 3초에 한번씩 네임노드에 HeartBeat 신호를 보냄. HeartBeat에는 디스크 가용 공간정보, 데이터 이동, 적재량 등의 정보가 들어있다.
  - **Block report**
  - **checksum** : 데이터를 저장할때 checksum을 같이 저장.
  - **Data Replication** : 데이터 노드로부터 'heartbeat'를 수신받지 못하면 그 데이터 노드는 죽은것으로 가정. 네임 노드는 죽은 데이터 노드가 이전에 보냈던 블록 리포트 정보를 참조하여 다른 데이터 노드에 복제를 결정


  ### Rack awareness
