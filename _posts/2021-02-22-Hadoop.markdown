---  
layout: post  
title: "Hadoop Ecosystem - HDFS"  
subtitle: "Hadoop Ecosystem -HDFS"  
categories: Data
tags: Engineering Hadoop HDFS MapReduce Spark
comments: true  


---  
## 하둡이란?

하둡은 대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈 소스 프레임워크. 하둡은 구글이 논문으로 발표한 GFS(Google File System) 과 맵리듀스(MapReduce)를 2005년 더그커팅이 구현한 결과물이다. 하둡은 분산시스템인 HDFS(Hadoop Distributed File System)에 데이터를 저장하고, 맵리듀스를 이용해 데이터를 처리한다.


## Hadoop의 3대 요소
  - 분산파일시스템(`HDFS`) - for 대용량
  - 분산병렬처리(`MapReduce`) - for 빠른계산
  - 하둡클러스터 자원관리시스템(`YARN`) - 클러스터 자원 스케줄링


## 분산파일시스템(HDFS)

#### HDFS 주요특징

- **대용량 데이터 저장**
- **데이터 무결성** - 한번 저장된 데이터는 수정할 수 없고 읽기만 가능. (이동 삭제 복사는 가능)
- **장애 복구**(고가용성)
- **스트리밍 방식의 데이터 접근** - 한번의 쓰기와 여러번의 읽기 데이터 접근 패턴을 가진다. 랜덤 엑세스 방식이 아니므로 빠르게 데이터에 접근하여 처리하기 보다는 대용량의 데이터를 순차적으로 처리

#### 네임노드와 데이터노드

하둡 분산 파일 시스템 클러스터는 일반적으로 `네임노드` 를 담당하는 서버가 한대 존재하며, 하나의 노드에 붙은 스토리지를 관리하는 수 많은 `데이터 노드` 로 구성이 됩니다. `데이터 노드` 에 `블록` 단위의 데이터들이 분산 저장되고 `네임노드` 의 관리에 의해 읽기 및 쓰기를 수행합니다.


- **네임노드(Master Node)** :
  -  **데이터 노드 관리** : `하트비트`와 `블록리포트`를 바탕으로 데이터 노드를 모니터링, 일정시간 하트비트가 도착하지 않으면 서버 장애 판단.
  - **블록 관리** : 장애가 발생한 데이터 노드의 블록을 새로운 `데이터 노드`로 복제. 용량이 부족한 `데이터 노드`가 있으면 여유가 있는 `데이터 노드`로 블록을 이동.
- **데이터노드(Slave Node)** : `네임노드`의 지시에 따라, 데이터들을 분산 저장하는 저장소
- **블록** : 64MB 혹은 128MB 단위의 `블록`으로 쪼개지고 복제(`3 copy`)되어 저장이 됨. `블록` 단위가 보통 디스크의 단위보다 큰 이유는 탐색비용을 최소화할 수 있으며, `메타데이터`의 크기를 줄일 수 있기 때문.

![hdfs1](https://yunsikus.github.io/assets/img/post_img/하둡3.jpg)

#### HDFS에 파일 저장하기

![hdfs2](https://yunsikus.github.io/assets/img/post_img/하둡1.jpg)

1. 클라이언트가 `네임노드`에 파일 저장을 요청. `네임노드`는 복제본 수와 동일한 수의 파이프라인을 형성. 다른 클라이언트가 해당 경로를 수정하지 못하도록 락을 검.  

2. 클라이언트는 첫 번째 `데이터 노드`에게 데이터를 전송

3. 첫번째 `데이터 노드`에서 데이터를 저장한 후, 데이터를 두번째 `데이터 노드`로 전송

4. 두번째 `데이터 노드`에서 데이터를 저장한 후, 데이터를 4번째 `데이터 노드`로 전송

5. 자기에게 데이터를 넘겨준 `데이터 노드`에게 저장이 완료되었음을 응답

7. 첫번째 `데이터 노드`는 클라이언트에게 파일 저장이 완료되었음을 응답


#### HDFS에 저장된 파일 읽기

![hdfs3](https://yunsikus.github.io/assets/img/post_img/하둡2.jpg)

1, 2) 클라이언트는 `네임노드`에게 요청된 파일이 어떤 블록에 저장되어 있는지 정보를 요청

3)  `메타데이터`를 통해 파일이 저장된 블록 리스트를 반환

4)  클라이언트는 `데이터 노드`에 접근하여 `블록` 조회 요청

5)  `데이터 노드`는 클라이언트에게 요청된 `블록`을 전송

### 장애처리

HDFS는 오류나 장애에 대한 해결책을 가지고 있습니다.

  - **HeartBeat**: `데이터 노드`에서 노드가 살아 있는 것을 알리기 위해 3초에 한번씩 `네임노드`에 `HeartBeat` 신호를 보냄. `HeartBeat`에는 디스크 가용 공간정보, 데이터 이동, 적재량 등의 정보가 들어있다.
  - **Block report** : 매 시간마다 `데이터 노드`에서 `네임 노드`로 `블록` 정보를 전달.
  - **checksum** : 데이터를 저장할때 용량(`checksum`)을 같이 저장. 데이터를 다시 불러올때 `checksum`과 용량이 다르면 다른 데이터 노드의 데이터를 가져온다.
  - **Data Replication** : 데이터 노드로부터 `heartbeat`를 수신받지 못하면 그 `데이터 노드`는 죽은것으로 가정. `네임 노드`는 죽은 `데이터 노드`가 이전에 보냈던 `블록 리포트 정보`를 참조하여 다른 `데이터 노드`에 복제를 결정


### Rack awareness
![hdfs3](https://yunsikus.github.io/assets/img/post_img/하둡4.jpg)

- **랙(Rack)** : 전산실을 구성할 때 작은 공간을 효율적으로 사용하고, 장비들을 안정적으로 보호하기 위해서 사용하는 도구로, 서버나 네트워크 장비들을 수용하기 위해서 사용하는 철제 프레임을 말합니다.

- **스위치(Switch)** : 네트워크 단위들을 연결하는 통신 장비

- `네임노드`는 `랙` 인식 방법에 따라 각각의 `데이터 노드`들이 설치된 `렉`을 구별합니다. 복사본을 서로 다른 `렉`에 위치시키는 것입니다. 이는 `랙` 전체에 장애가 발생했을때 데이터 손실을 방지하고, 데이타 읽기 시 복수개의 렉의 대역폭을 활용하도록 합니다.

- 일반적으로 복사개수가 3일때, HDFS의 배치정책은 하나의 사본을 동일 랙에 위치한 노드에 저장하고, 또하나는 동일 랙의 다른 노드에 저장하며, 마지막 하나는 다른 랙에 노드에 저장합니다.
